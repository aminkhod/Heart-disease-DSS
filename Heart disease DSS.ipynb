{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7976e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d7d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getType():\n",
    "#     global max_days\n",
    "#     if MaxDays.get() == \"\":\n",
    "#         max_days = \"3,10\"\n",
    "#     else:\n",
    "#         max_days = MaxDays.get()\n",
    "\n",
    "def Heart_Disease_Data():\n",
    "    global dfSM\n",
    "    print('Decision Support System(DSS) :-)')\n",
    "    import_file_path = filedialog.askopenfilename()\n",
    "    print('Importing...')\n",
    "    print('Please Wait :)')\n",
    "    missing_values = [\"n/a\", \"na\", \"--\", \"nan\", \".\", \"-\", \"- \", \"_\"]\n",
    "    dfSM = pd.read_excel(import_file_path, na_values=missing_values)\n",
    "    print('Decision Support System(DSS) has been uploaded')\n",
    "\n",
    "def To_predictData():\n",
    "    global preData\n",
    "    print('Data to predict :-)')\n",
    "    import_file_path = filedialog.askopenfilename()\n",
    "    print('Importing...')\n",
    "    print('Please Wait :)')\n",
    "    missing_values = [\"n/a\", \"na\", \"--\", \"nan\", \".\", \"-\", \"- \", \"_\"]\n",
    "    preData = pd.read_excel(import_file_path, na_values=missing_values)\n",
    "    print('Data to predict has been uploaded')\n",
    "    print('Files have been Imported\\nClick Run and close the window!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1151db6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Import Excel Files\n",
      "Decision Support System(DSS) :-)\n",
      "Importing...\n",
      "Please Wait :)\n",
      "Decision Support System(DSS) has been uploaded\n",
      "Decision Support System(DSS) :-)\n",
      "Importing...\n",
      "Please Wait :)\n",
      "Decision Support System(DSS) has been uploaded\n",
      "Data to predict :-)\n",
      "Importing...\n",
      "Please Wait :)\n",
      "Data to predict has been uploaded\n",
      "Files have been Imported\n",
      "Click Run and close the window!\n"
     ]
    }
   ],
   "source": [
    "print('Please Import Excel Files')\n",
    "\n",
    "root = tk.Tk()\n",
    "root.geometry('550x400')\n",
    "root.title(\"Decision Support System(DSS)\")\n",
    "\n",
    "label_0 = tk.Label(root, text=\"Heart Disease Recognition\", relief=\"solid\", width=30, font=(\"arial\", 19, \"bold\"))\n",
    "label_0.place(x=300, y=100, anchor=\"center\")\n",
    "\n",
    "# MaxDays = tk.StringVar()\n",
    "# LMaxDays = tk.Label(root, text=\"Max Days: \", width=10, font=(\"bold\", 10))\n",
    "# LMaxDays.place(x=175, y=270, anchor=\"center\")\n",
    "# EMaxDays = tk.Entry(root, textvar=MaxDays, width=5)\n",
    "# EMaxDays.place(x=235, y=270, anchor=\"center\")\n",
    "\n",
    "# max_days = None\n",
    "dfSM = None\n",
    "preData = None\n",
    "# df_scheme= None\n",
    "# df_ride= None\n",
    "\n",
    "Get_List = tk.Button(root, text='Heart Disease Data', width=20, bg='brown', fg='white',\n",
    "                     command=Heart_Disease_Data).place(x=300, y=200, anchor=\"center\")\n",
    "\n",
    "Get_List = tk.Button(root, text='Data to predict', width=20, bg='brown', fg='white',\n",
    "                     command=To_predictData).place(x=300, y=250, anchor=\"center\")\n",
    "\n",
    "Get_Max = tk.Button(root, text='Run', width=15, bg='green', fg='white').place(x=300, y=350, anchor=\"center\")\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "# del Get_List\n",
    "# del Get_Ride\n",
    "# del Get_Max\n",
    "# del Get_DailyFraud\n",
    "# del Get_HistFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a861ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "XSM = dfSM.drop('Target', axis=1)\n",
    "ySM = dfSM['Target']\n",
    "\n",
    "SS = StandardScaler()\n",
    "SS.fit(XSM)\n",
    "X_normal_SM = SS.transform(XSM)\n",
    "X_normal_SM = pd.DataFrame(X_normal_SM)\n",
    "dfSM = pd.concat([X_normal_SM, ySM], axis=1)\n",
    "col = list(set(XSM.columns))\n",
    "col.append('Target')\n",
    "dfSM.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97fbc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfSM.iloc[:,-1].values\n",
    "X = dfSM.drop('Target',axis=1).values\n",
    "\n",
    "pso = np.array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "X_selected_features = X[:,pso==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d756c5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:21:48] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLF = XGBClassifier()\n",
    "CLF.fit(X_selected_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d578b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  approach2_impute_metric(messy_df, metric):\n",
    "    # Finding columns which have null values\n",
    "    colnames = []\n",
    "    for col in messy_df.columns:\n",
    "        if messy_df[col].isnull().sum() > 0:\n",
    "            colnames.append(col)\n",
    "    if len(colnames) == 0:\n",
    "        return messy_df, []\n",
    "    # Create X_df of predictor columns\n",
    "    X_df = messy_df.drop(colnames, axis = 1)\n",
    "    \n",
    "    # Create Y_df of predicted columns\n",
    "    Y_df = messy_df[colnames]\n",
    "        \n",
    "    # Create empty dataframes and list\n",
    "    Y_pred_df = pd.DataFrame(columns=colnames)\n",
    "    Y_missing_df = pd.DataFrame(columns=colnames)\n",
    "    missing_list = []\n",
    "    \n",
    "    # Loop through all columns containing missing values\n",
    "    for col in messy_df[colnames]:\n",
    "    \n",
    "        # Number of missing values in the column\n",
    "        missing_count = messy_df[col].isnull().sum()\n",
    "        \n",
    "        # Separate train dataset which does not contain missing values\n",
    "        messy_df_train = messy_df[~messy_df[col].isnull()]\n",
    "        \n",
    "        # Create X and Y within train dataset\n",
    "        msg_cols_train_df = messy_df_train[col]\n",
    "        messy_df_train = messy_df_train.drop(colnames, axis = 1)\n",
    "\n",
    "        # Create test dataset, containing missing values in Y    \n",
    "        messy_df_test = messy_df[messy_df[col].isnull()]\n",
    "        \n",
    "        # Separate X and Y in test dataset\n",
    "        msg_cols_test_df = messy_df_test[col]\n",
    "        messy_df_test = messy_df_test.drop(colnames,axis = 1)\n",
    "\n",
    "        # Copy X_train and Y_train\n",
    "        Y_train = msg_cols_train_df.copy()\n",
    "        X_train = messy_df_train.copy()\n",
    "        \n",
    "        # Linear Regression model\n",
    "        if metric == \"Linear Regression\":\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train,Y_train)\n",
    "            print(\"R-squared value is: \" + str(model.score(X_train, Y_train)))\n",
    "          \n",
    "        # Random Forests regression model\n",
    "        elif metric == \"Random Forests\":\n",
    "            model = RandomForestRegressor(n_estimators = 50 , oob_score = True, max_depth=10)\n",
    "            model.fit(X_train,Y_train) \n",
    "                   \n",
    "        X_test = messy_df_test.copy()\n",
    "        # Predict Y_test values by passing X_test as input to the model\n",
    "        Y_test = model.predict(X_test)\n",
    "        \n",
    "        Y_test_integer = pd.to_numeric(pd.Series(Y_test),downcast='integer')\n",
    "        \n",
    "        # Append predicted Y values to known Y values\n",
    "        Y_complete = Y_train.append(Y_test_integer)\n",
    "        Y_complete = Y_complete.reset_index(drop = True)\n",
    "        \n",
    "        # Update list of missing values\n",
    "        missing_list.append(Y_test.tolist())\n",
    "        \n",
    "        Y_pred_df[col] = Y_complete\n",
    "        Y_pred_df = Y_pred_df.reset_index(drop = True)\n",
    "    \n",
    "    # Create cleaned up dataframe\n",
    "    clean_df = X_df.join(Y_pred_df)\n",
    "    \n",
    "    return clean_df,missing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aece1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    preData = preData.drop('Unnamed: 0', axis=1)\n",
    "except:\n",
    "    1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523bf680",
   "metadata": {},
   "outputs": [],
   "source": [
    "preData = preData.rename(columns={\n",
    "                       'جنس': 'Sex',\n",
    "                       'سن': 'Age',\n",
    "                       'C':'Target',\n",
    "                       'تعداد روزهای بستری':'Number of hospitalization days',\n",
    "                       'نبض':'Heart rate',\n",
    "                       'دیابت':'Diabetes',\n",
    "                       'فشار خون سیستولیک':'BPs',\n",
    "                       'فشار خون دیاستولیک':'BPd',\n",
    "                      'درد قفسه سینه':'Chest pain',\n",
    "                      'سیگار':'Smoke',\n",
    "                      'سابقه تنگی نفس':'History of shortness of breath',\n",
    "                      'سابقه بیماری قلبی':'History of heart disease',\n",
    "                      'سابقه فامیلی بیماری قلبی':'Family history of heart disease',\n",
    "                      'سابقه فشار خون':'History of high blood pressure'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7acf2459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32226/3993921093.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  preData['Sex'][preData['Sex']=='زن']=0\n",
      "/tmp/ipykernel_32226/3993921093.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  preData['Sex'][preData['Sex']=='مرد']=1\n",
      "/tmp/ipykernel_32226/3993921093.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  preData['Sex'][preData['Sex']=='مرد ']=1\n"
     ]
    }
   ],
   "source": [
    "preData['Sex'][preData['Sex']=='زن']=0\n",
    "preData['Sex'][preData['Sex']=='مرد']=1\n",
    "preData['Sex'][preData['Sex']=='مرد ']=1\n",
    "preData['Sex'] = preData['Sex'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67627b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDF, mislist = approach2_impute_metric(preData,\"Random Forests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1723831c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b80cda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardizedData = SS.transform(preData)\n",
    "y = CLF.predict(StandardizedData[:,pso==1])\n",
    "\n",
    "# y = CLF.predict(cleanDF.values[:,pso==1])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a770d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDF['predict'] = y\n",
    "cleanDF.to_excel('Result.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288df88a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
